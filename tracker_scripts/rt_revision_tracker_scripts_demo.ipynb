{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Track Dev Branch Commits.\n",
    "- Extract single file daily & parse\n",
    "- Client makes a direct request for rt.sh from GitHub\n",
    "- rt.sh is read, preprocessed & extracts the timestamps of the relevant datasets which has been pushed on GitHub.\n",
    "- Generates a file containing the datasets' timestamps\n",
    "- Program will compare the last log file with the most recent file containing the datasets' timestamps.\n",
    "\n",
    "### Setting up the environment\n",
    "Once you have conda installed on your machine, perform the following to create a conda environment: ++\n",
    "- Create environment with .yml. Note: Environemnt name is set within the yml file\n",
    "    - $ conda env create -f git_env.yml\n",
    "\n",
    "- Activate the new environment via:\n",
    "   - $ conda activate data_tracker\n",
    "   \n",
    "- Verify that the new environment was installed correctly via:\n",
    "    - $ conda info --env\n",
    "\n",
    "- Confirm the git-env.yml dependencies were installed via:\n",
    "    - $ conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rt_revision_tracker import *\n",
    "\n",
    "# Restart the accumulation of timestamps.\n",
    "rt_revision_tracker().reset_tracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rt_revision_tracker import *\n",
    "\n",
    "# Accumulation of timestamps since time of reset.\n",
    "data_log_dict = rt_revision_tracker().populate()\n",
    "data_log_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Window Featuring Latest 2 Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Window to Filter dataset by retrieval date duration\n",
    "# In this scenario, capturing the past 60 days of data.\n",
    "from rt_tracker_filter import RtTrackerFilter\n",
    "maintenance_wrapper =  RtTrackerFilter()\n",
    "maintenance_wrapper.maintenance_window(60)\n",
    "window_dates2store = maintenance_wrapper.maintenance_window_dict\n",
    "window_dates2store \n",
    "\n",
    "# TODO: For data maintenance & preserving current data managment process, if the retrieval date is not within\n",
    "# cloud data storage, then remove the objects with the prefix dates outside of filter window from cloud data storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the latest pickle from data tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Recall latest updated file & populate w/ retrieved file if it has a timestamp revision.\n",
    "with open(\"./track_ts/latest_rt.sh.pk\", 'rb') as handle:\n",
    "    data_log_dict = pickle.load(handle)                \n",
    "print('\\033[94m' + '\\033[1m' + f'\\nTimestamps (Prior to File Retrieval):\\033[0m\\033[1m\\n{data_log_dict}\\033[0m')  \n",
    "\n",
    "# Map dictionary keys to the established ts names as shown on data folders on-prem.\n",
    "data_fldrs_dict = {}\n",
    "for retrieval_date, ts_dict in data_log_dict.items():\n",
    "    \n",
    "    # Initialize the list per retrieval day\n",
    "    input_ts, bl_ts, ww3_input_ts, bmic_ts = [], [], [], []\n",
    "    for ts_type, ts_day in ts_dict.items():\n",
    "        for ts in ts_day:\n",
    "            if ts_type == 'BL_DATE' and f'develop-{ts}' not in bl_ts:\n",
    "                bl_ts.append(f'develop-{ts}')\n",
    "            elif ts_type == 'INPUTDATA_ROOT' and f'input-data-{ts}' not in input_ts:\n",
    "                input_ts.append(f'input-data-{ts}')\n",
    "            elif ts_type == 'INPUTDATA_ROOT_BMIC' and f'BM_IC-{ts}' not in bmic_ts:\n",
    "                bmic_ts.append(f'BM_IC-{ts}')\n",
    "            elif ts_type == 'INPUTDATA_ROOT_WW3' and f'WW3_input_data_{ts}' not in ww3_input_ts:\n",
    "                 ww3_input_ts.append(f'WW3_input_data_{ts}')\n",
    "    data_fldrs_dict[retrieval_date] = input_ts, bl_ts, ww3_input_ts, bmic_ts\n",
    "data_fldrs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest retrival date. \n",
    "input_ts, bl_ts, ww3_input_ts, bmic_ts = data_fldrs_dict[max(data_fldrs_dict)]\n",
    "input_ts, bl_ts, ww3_input_ts, bmic_ts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "- BL dataset timestamps will not necessarily sync up with the date at which PR was approved - can take unknown N days to approve.\n",
    "\n",
    "- Baseline change label does not necessarily ensure date was actually change\n",
    "\n",
    "- 'BM_IC' # IC folder's prefix\n",
    "\n",
    "- 'develop' # Baseline folder's prefix\n",
    "\n",
    "- 'input-data' # Input folder's prefix\n",
    "\n",
    "- 'WW3_input_data' # WW3 Input folder's prefix\n",
    "\n",
    "#### Suggestion:\n",
    "- Why not name the datasets based on the date at which they were approved? Would allow a script to collect based on PR approved date - assuming baseline github labels are properly labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'BM_IC' # IC folder's prefix\n",
    "'develop' # Baseline folder's prefix\n",
    "'input-data' # Input folder's prefix\n",
    "'WW3_input_data' # WW3 Input folder's prefix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_tracker",
   "language": "python",
   "name": "data_tracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
